# The Guardian Appeal

## Mira / Yusuf

---

The resolution window had closed that morning. Seventy-one point four percent—the final tally, now locked. NG-2047-31 was formally passed.

They were in the receiving room at Lapita Horizons. The vote itself had been no surprise—they'd known for days it would clear the threshold. What mattered now was what came next.

"The Guardians confirmed the hearing," Mira said. She was standing by the window, watching the Pacific. The waves were high today—a storm cycle she'd programmed to test the erosion rates on the eastern seawall. "Three days from now. They've asked whether we want to present remotely or in person."

"In person," Yusuf said immediately. "Four days of transit, but it's the right call."

No one disagreed. In a world where anyone could appear anywhere without effort via an avatar, choosing to travel was itself a statement. The Guardians would hear the same words either way—but they'd know Mira and Yusuf had spent days in transit to deliver them.

"Kenji and I will run the end user veto campaign while you're gone," Elena said. "I haven't been able to arrange a meeting yet with the Executive."

"If we fail with the Guardians," Mira said, "you'll need those fourteen million users to be more than just spectators."

"Then don't fail." Kenji's voice was light, but his eyes weren't.

---

The transit took two days.

They spent most of it preparing. Mira refined the core argument—pluralism, reversibility, the danger of path-dependency. Yusuf worked his own angle: the history of the network, the founding principles, the moments when standardization had been proposed before and rejected. He dug through old governance records the way he dug through soil—methodically, looking for ideas in the trash heaps of history. Outside, the stars held steady, no atmosphere to make them twinkle.

"They're going to say we're relics," Yusuf said on the second day.

"We are relics," Mira replied. "That's the point. We remember why the foundations were built the way they were. The question is whether the Guardians care about foundations."

---

The Triad Chamber was a modest station in a separate orbit from the Operating Company's Axis—deliberately so. The Guardians maintained their own infrastructure, independent from the network's administrative machinery. The station was smaller than Mira had expected, functional rather than impressive. The air smelled of recycled nitrogen and something faintly botanical, as if someone had insisted on plants.

The Guardian Triad met in a room that felt like a deliberate echo of an older era: heavy wood tables, high ceilings, and a silence that felt engineered.

Three figures sat across from them.

To the left, the **Legacy Guardian**. A man who looked like he’d been carved out of dry Earth, his face a map of lines that were a deliberate choice in an era of longevity treatments. He was a founder, a peer, someone who remembered the Convergence as a lived experience rather than a historical data point.

To the right, the **Contemporary Trust Guardian**. Younger, sharp-eyed, her posture radiating the restless energy of a generation that viewed "founder authority" with deep suspicion. She was there to ensure the network didn't become a museum for its creators.

In the center, the **AI Guardian**. It didn't have a body, only a presence—a soft, multi-layered geometric projection that pulsed with a steady, neutral light. The projection was local; the AI itself ran on the station's independent systems, deliberately isolated from the Operating Company's infrastructure. It had access to every governance failure in human history, every record of institutional drift, and a processing capacity that made Mira's simulation swarms look like abacuses.

Mira stood before them, Yusuf at her shoulder. They wore their field clothes—scuffed boots, durable fabrics, the gear of people who worked in worlds where things broke.

"The proposal NG-2047-31 frames itself as a quality standard," Mira began. "But its effect is the elimination of pluralism. If it stands, the network will mandate one approach and prohibit its alternative. The network's future will be narrower than its past." She paused. "We're asking you to block it."

The Contemporary Trust Guardian tilted her head. "The operator vote was seventy-one percent. You're asking us to overrule a supermajority."

"We're asking you to look at *what* they voted on," Yusuf said. His voice was a low rumble, but precise. "The founding charter—Article 2, Section 1—establishes the network's purpose as 'preserving and transmitting the full range of human experience across time.' Not the safe range. The full range."

The Legacy Guardian shifted in his seat. "I remember the debates over that language. But when we had that discussion, we mostly had in mind whether we would privilege cerrtain times and places."

"That's not how I saw it, or talked about it. Yes, there was that, but 'Full range' included risk. Consequence. The possibility of genuine harm. We didn't accidentally leave the door open for permissive-tier experiences—we built the door."

"That's ancient history, Yusuf."

"It's the charter. The current proposal doesn't clarify network identity—it *amends* it. But it's been framed as policy rather than principle, so the operators voted on a technical question when they were actually deciding something foundational."

The AI Guardian's projection pulsed. "The framing argument has merit. If the proposal effectively amends the charter's scope, the operators may not have understood what they were voting on."

"May have been," the Legacy Guardian said. "That's not your call to make unilaterally."

"I am not making it unilaterally. I am noting that the framing shaped the outcome, as did the timing."

Mira stepped forward. "This is what we're trying to show you. The operators voted honestly—for less liability, less friction. But they weren't asked whether they wanted to amend the network's founding purpose. If the proposal had framed it that way—'strike full range, replace with safe range'—you wouldn't have gotten seventy-one percent."

"You don't know that," the Trust Guardian said.

"I know operators," Mira said. "Most of them don't want to eliminate the alternative. They just want to protect themselves. The framing gave them permission to vote for safety without feeling like they were voting against freedom. That's capture. Not by conspiracy—by tempo and language."

The AI Guardian's layers rotated slowly. "I consider the argument for pluralism sound. A system that prohibits its own alternatives loses adaptive capacity. By eliminating permissive-tier experiences, the network loses the ability to model high-stakes human behavior. This represents a significant loss of systemic resilience."

The Trust Guardian frowned. "You're saying we should block because of... future optionality?"

"I am saying the proposal creates a path-dependency that is difficult to reverse. We should should weigh that in."

Silence. Mira felt a spark of hope. She hadn't expected the AI Guardian to offer this line of resoning.

But the Trust Guardian was shaking her head.

"The charter says 'full range,'" Yusuf pressed, before she could speak.

She tilted her head. "Let me ask you something. In your sanctuaries—do visitors eat meat?"

Yusuf blinked. "What?"

"Beef. Pork. Chicken. Animals with nervous systems, raised and slaughtered. That's historically accurate for most periods you reconstruct. Do your visitors participate in that?"

"No. We use cultured proteins styled to period presentation."

"And in your sanctuaries, Mira—visitors hunt, don't they? They fish?"

Mira nodded slowly. "But the animals they catch—they don't have nervous systems. The fish fight on the line, the boar charges, but there's nothing experiencing the death. It's theater." She met the Guardian's eyes. "That's a concession to arealism on my part. I know it. The real Lapita of history ate real fish."

"So you accept that some principles are sufficiently important to outweigh realism," the Trust Guardian said. "The principle that we don't kill sentient creatures for recreation—that's important enough to you that you'll sacrifice historical accuracy for it."

"Yes."

"Then this isn't a debate about whether limits exist. It's a debate about where to put them." She leaned forward. "You've chosen not to let visitors kill sentient creatures. The operators have chosen not to let visitors break their own bones. Both are limits. Both involve trade-offs. The question is: who decides which trade-off is correct?"

Mira paused and thought. "The difference is agency. The animals in my sanctuaries can't consent—they have no capacity to choose risk. But my visitors can. They're cognizant adults. They understand the terms. When Solène signed her waiver, she was exercising her own judgment about what she was willing to experience. The animals I don't kill have no such capacity. That's the line."

The Legacy Guardian spoke for the first time in a while. "I reviewed the Lapita incident logs, Mira. All of them. I watched Solène Varga carried out with a compound fracture, screaming that she didn't want to leave." He leaned forward. "She signed a waiver. She exercised agency. And then, in the moment, she begged your staff not to extract her—and they did it anyway, because the network's protocols required it. The network already overrides visitor agency when it judges the situation requires it. The question isn't whether we respect agency. It's whose judgment prevails when agency and safety conflict."

Mira didn't answer.

"The operators who voted for this proposal—they're not villains. They've watched visitors get hurt. They've had to make the call to extract someone against their will. They're telling us they don't want to carry that weight anymore."

"They're also telling us they don't want competition from approaches that take more risk," Yusuf said.

"Maybe. But seventy-one percent of them made the same judgment. These are practitioners, Yusuf. Your colleagues. When that many of them say 'we've seen enough harm,' I take that seriously."

"And you're weighing safety and operator voice higher than pluralism," Mira said quietly.

"Yes." The Legacy Guardian met her eyes. "I am. Not because I think you're wrong about the long-term effects. But because real people have been hurt, and the people closest to that harm have asked us to change course. I can't dismiss that."

"But that's not what the proposal *does*." Yusuf's voice was sharp. "If this were about safety, it would restrict permissive-tier experiences. It would set limits on physical risk. Instead, it mandates Essentialism as the only acceptable approach. That's not a safety standard—it's an aesthetic choice."

The Trust Guardian frowned. "The proposal establishes quality frameworks—"

"The proposal eliminates Realism as a methodology," Yusuf interrupted. "You can have safe Realist sanctuaries. Mira runs them. Most of her visitors never enter permissive tier. But under this proposal, her entire approach becomes non-compliant—not because it's dangerous, but because it prioritizes historical fidelity over emotional curation." He looked at the Legacy Guardian. "The safety arguments are real. I'm not dismissing them. But they're being used to justify something larger. The proposal doesn't just restrict risk—it mandates a particular philosophy of what sanctuaries should *be*."

The Legacy Guardian was quiet for a moment. "Even if that's true—and I'm not conceding it is—the operators voted for the proposal as written. They knew what they were voting on."

"Did they? Or did the safety framing give them permission to vote for something they wouldn't have supported if it had been presented honestly—as a choice between two legitimate artistic traditions?"

Silence.

The Trust Guardian glanced at her colleagues. "We'll deliberate. Please wait outside."

---

The chamber doors slid shut. Mira and Yusuf stood in the corridor, waiting.

Inside, the three Guardians faced each other across the curved table.

"The conflation argument has merit," the AI Guardian said. Its projection had shifted to a denser configuration—deliberation mode. "The proposal uses safety concerns to mandate a methodological preference. These are separable issues. A safety-focused proposal would restrict permissive-tier experiences. This proposal eliminates an entire approach to sanctuary design."

"Even so," the Legacy Guardian said, "the operators voted for the proposal as written. We can't assume they were confused."

"We can note the ambiguity. The framing shaped the outcome. If the proposal had been presented more clearly as 'Essentialism over Realism' rather than being muddied by 'safety standards,' the vote might have been different."

The Trust Guardian shook her head. "Might. We don't know. And we can't block a supermajority vote on the basis of speculation about what operators *would* have done under different framing."

"Then consider systemic resilience," the AI said. "A network that eliminates its own alternatives loses adaptive capacity. This is a path-dependency that will be difficult to reverse. I assess this as a significant loss."

"I hear you," the Legacy Guardian said. "But I'm weighing that against real harm. Solène Varga's compound fracture. The operators who've had to make extraction calls against visitors' wishes. The safety concerns aren't manufactured—they're responses to actual incidents."

"The safety concerns are real," the AI agreed. "But they could be addressed without mandating a particular aesthetic philosophy. The proposal does more than it needs to."

The Trust Guardian leaned back. "Here's my concern. If we block this, we're saying that three Guardians—two humans and an AI—know better than seventy-one percent of the practitioners who actually run sanctuaries. That's a hard position. The operators aren't passive. They deliberated. They voted. They're telling us what they want."

"They're telling us what they were asked," the AI said. "The question is whether what they were asked was the right question."

"That's not our call." The Legacy Guardian's voice was tired but firm. "Our role is to check for capture, for bad faith, for process failures. I don't see those here. I see a community making a choice I might disagree with. That's not the same thing."

The AI's light dimmed slightly. "I will dissent on the record. But I acknowledge the human Guardians are acting within their judgment, not in bad faith."

"Noted." The Trust Guardian stood. "Let's bring them back in."

---

The doors opened. Mira and Yusuf returned to find the Guardians standing.

The Legacy Guardian spoke. "The Triad has deliberated. By a vote of two to one, the appeal is denied. The proposal NG-2047-31 will proceed to implementation."

Mira's face didn't change, but Yusuf saw her hands tighten at her sides.

"I will read the decision into the record," the Trust Guardian said. "The Triad acknowledges the appellants' concerns regarding systemic resilience, adaptive capacity, and the conflation of safety standards with methodological preference. These concerns have merit and are noted for future governance review. However, the Triad finds no sufficient basis to override a seventy-one percent operator vote. The operators are the practitioners closest to the work; their collective judgment, expressed through proper process, carries significant weight. We do not find evidence of bad faith, procedural failure, or institutional capture sufficient to justify intervention."

She paused. "The AI Guardian dissents. Its position—that systemic resilience and adaptive capacity are underweighted, and that the conflation of safety with methodology creates ambiguity about what operators endorsed—is recorded."

The Legacy Guardian stepped forward. "Mira, Yusuf. The Triad's decision is not the final word. The User Veto remains available. If two-thirds of active end-users—fourteen million people who have visited sanctuaries in the past year—vote to override the proposal, it will be struck down. This mechanism exists precisely for situations where the operators and the users may have different interests."

"The User Veto has never been successfully invoked," Mira said.

"No," the Legacy Guardian said. "It hasn't. But the mechanism exists. If you believe the users share your concerns, that is the appropriate path."

---

The doors to the chamber slid shut behind them.

"Two to one." Yusuf felt sad, yes, but also bemused. "We got the AI on our side. I didn't expect that."

Mira started toward the transit docks. "The Guardians made a principled choice. I don't agree with it, but I understand it. They're weighing operator voice and demonstrated harm. We're weighing systemic resilience and founding principles. Different weights, same values."

"So what now?"

Mira looked at her hands—steady, practiced, the hands of someone who built worlds. "Now we see if anyone is actually paying attention."
